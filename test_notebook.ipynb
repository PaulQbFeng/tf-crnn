{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/notebooks/models/research/slim/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "try:\n",
    "    import better_exceptions\n",
    "except ImportError:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "from src.model import crnn_fn\n",
    "from src.data_handler import make_input_fn\n",
    "from src.data_handler import preprocess_image_for_prediction\n",
    "\n",
    "from src.config import Params, import_params_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_cnn(input_imgs: tf.Tensor, is_training=False, summaries=False):\n",
    "    \n",
    "    input_tensor = input_imgs\n",
    "    if input_tensor.shape[-1] == 1:\n",
    "        input_channels = 1\n",
    "    elif input_tensor.shape[-1] == 3:\n",
    "        input_channels = 3\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Following source code, not paper\n",
    "\n",
    "    with tf.variable_scope('deep_cnn'):\n",
    "        # - conv1 - maxPool2x2\n",
    "        with tf.variable_scope('layer1'):\n",
    "            W = weightVar([3, 3, input_channels, 64])\n",
    "            b = biasVar([64])\n",
    "            conv = conv2d(input_tensor, W, name='conv')\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            conv1 = tf.nn.relu(out)\n",
    "            pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name='pool')\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer1/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer1/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "\n",
    "        # - conv2 - maxPool 2x2\n",
    "        with tf.variable_scope('layer2'):\n",
    "            W = weightVar([3, 3, 64, 128])\n",
    "            b = biasVar([128])\n",
    "            conv = conv2d(pool1, W)\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            conv2 = tf.nn.relu(out)\n",
    "            pool2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME', name='pool1')\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer2/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer2/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        # - conv3 - w/batch-norm (as source code, not paper)\n",
    "        with tf.variable_scope('layer3'):\n",
    "            W = weightVar([3, 3, 128, 256])\n",
    "            b = biasVar([256])\n",
    "            conv = conv2d(pool2, W)\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                                   training=is_training, name='batch-norm')\n",
    "            conv3 = tf.nn.relu(b_norm, name='ReLU')\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer3/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer3/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        # - conv4 - maxPool 2x1\n",
    "        with tf.variable_scope('layer4'):\n",
    "            W = weightVar([3, 3, 256, 256])\n",
    "            b = biasVar([256])\n",
    "            conv = conv2d(conv3, W)\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            conv4 = tf.nn.relu(out)\n",
    "            pool4 = tf.nn.max_pool(conv4, [1, 2, 2, 1], strides=[1, 2, 1, 1],\n",
    "                                   padding='SAME', name='pool4')\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer4/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer4/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        # - conv5 - w/batch-norm\n",
    "        with tf.variable_scope('layer5'):\n",
    "            W = weightVar([3, 3, 256, 512])\n",
    "            b = biasVar([512])\n",
    "            conv = conv2d(pool4, W)\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                                   training=is_training, name='batch-norm')\n",
    "            conv5 = tf.nn.relu(b_norm)\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer5/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer5/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        # - conv6 - maxPool 2x1 (as source code, not paper)\n",
    "        with tf.variable_scope('layer6'):\n",
    "            W = weightVar([3, 3, 512, 512])\n",
    "            b = biasVar([512])\n",
    "            conv = conv2d(conv5, W)\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            conv6 = tf.nn.relu(out)\n",
    "            pool6 = tf.nn.max_pool(conv6, [1, 2, 2, 1], strides=[1, 2, 1, 1],\n",
    "                                   padding='SAME', name='pool6')\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer6/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer6/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        # - conv 7 - w/batch-norm (as source code, not paper)\n",
    "        with tf.variable_scope('layer7'):\n",
    "            W = weightVar([2, 2, 512, 512])\n",
    "            b = biasVar([512])\n",
    "            conv = conv2d(pool6, W, padding='VALID')\n",
    "            out = tf.nn.bias_add(conv, b)\n",
    "            b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                                   training=is_training, name='batch-norm')\n",
    "            conv7 = tf.nn.relu(b_norm)\n",
    "\n",
    "            if summaries:\n",
    "                weights = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer7/weights:0'][0]\n",
    "                tf.summary.histogram('weights', weights)\n",
    "                bias = [var for var in tf.global_variables() if var.name == 'deep_cnn/layer7/bias:0'][0]\n",
    "                tf.summary.histogram('bias', bias)\n",
    "\n",
    "        cnn_net = conv7\n",
    "\n",
    "        with tf.variable_scope('Reshaping_cnn'):\n",
    "            shape = cnn_net.get_shape().as_list()  # [batch, height, width, features]\n",
    "            transposed = tf.transpose(cnn_net, perm=[0, 2, 1, 3],\n",
    "                                      name='transposed')  # [batch, width, height, features]\n",
    "            conv_reshaped = tf.reshape(transposed, [shape[0], -1, shape[1] * shape[3]],\n",
    "                                       name='reshaped')  # [batch, width, height x features]\n",
    "\n",
    "    return conv_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /notebooks/samples/0.png /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "\n",
    "def resize_img(img):\n",
    "    return transform.rescale(img, 384 / img.shape[1], mode='constant', cval=255, clip=True, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256)\n",
      "(1, 48, 384, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('/tmp/0.png', 0)[:32,:256]\n",
    "plt.imshow(img)\n",
    "\n",
    "print(img.shape)\n",
    "img = resize_img(img).reshape(1,-1,384,1)\n",
    "# img = img.reshape(1,32,-1,1).astype(np.float32)\n",
    "\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightVar(shape, mean=0.0, stddev=0.02, name='weights'):\n",
    "    init_w = tf.truncated_normal(shape=shape, mean=mean, stddev=stddev)\n",
    "    return tf.Variable(init_w, name=name)\n",
    "\n",
    "\n",
    "def biasVar(shape, value=0.0, name='bias'):\n",
    "    init_b = tf.constant(value=value, shape=shape)\n",
    "    return tf.Variable(init_b, name=name)\n",
    "\n",
    "\n",
    "def conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME', name=None):\n",
    "    return tf.nn.conv2d(input, filter, strides=strides, padding=padding, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    conv = deep_cnn(img.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deep_cnn/Reshaping_cnn/reshaped:0' shape=(1, 31, 512) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet-101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets.resnet_v1 import resnet_v1_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_cnn(cnn_input: tf.Tensor):\n",
    "    with tf.variable_scope('Reshaping_cnn'):\n",
    "        shape = cnn_input.get_shape().as_list()  # [batch, height, width, features]\n",
    "        transposed = tf.transpose(cnn_input, perm=[0, 2, 1, 3],\n",
    "                                  name='transposed')  # [batch, width, height, features]\n",
    "        conv_reshaped = tf.reshape(transposed, [shape[0], -1, shape[1] * shape[3]],\n",
    "                                   name='reshaped')  # [batch, width, height x features]\n",
    "    return conv_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resnet_v1_101/block4/unit_3/bottleneck_v1/Relu:0\", shape=(1, 2, 12, 2048), dtype=float64)\n",
      "Tensor(\"Reshaping_cnn/reshaped:0\", shape=(1, 12, 4096), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    conv_res,_ = resnet_v1_101(img, global_pool=False, on_text=False)\n",
    "    print(conv_res)\n",
    "    conv_res = reshape_cnn(conv_res)\n",
    "    print(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshaping_cnn/reshaped:0\", shape=(1, 4, 2048), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resnet_v1_101/block4/unit_3/bottleneck_v1/Relu:0\", shape=(1, 2, 95, 2048), dtype=float64)\n",
      "Tensor(\"Reshaping_cnn/reshaped:0\", shape=(1, 95, 4096), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    conv_res_on_text,_ = resnet_v1_101(img, global_pool=False, on_text=True)\n",
    "    print(conv_res_on_text)\n",
    "    conv_res_on_text = reshape_cnn(conv_res_on_text)\n",
    "    print(conv_res_on_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshaping_cnn/reshaped:0' shape=(1, 64, 4096) dtype=float64>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_res_on_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
